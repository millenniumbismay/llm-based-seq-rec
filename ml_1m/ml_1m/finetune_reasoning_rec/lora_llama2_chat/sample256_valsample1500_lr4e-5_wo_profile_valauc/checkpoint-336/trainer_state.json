{
  "best_metric": 0.7683358859729006,
  "best_model_checkpoint": "./lora_llama2_chat/sample256_valsample1500_lr4e-5_wo_profile_valauc/checkpoint-336",
  "epoch": 7.813953488372093,
  "eval_steps": 42,
  "global_step": 336,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.23,
      "learning_rate": 1.904761904761905e-05,
      "loss": 1.2005,
      "step": 10
    },
    {
      "epoch": 0.47,
      "learning_rate": 3.80952380952381e-05,
      "loss": 1.1416,
      "step": 20
    },
    {
      "epoch": 0.7,
      "learning_rate": 3.991586819350316e-05,
      "loss": 1.065,
      "step": 30
    },
    {
      "epoch": 0.93,
      "learning_rate": 3.9822388408506664e-05,
      "loss": 0.9519,
      "step": 40
    },
    {
      "epoch": 0.98,
      "eval_auc": 0.6536878742721527,
      "eval_loss": 0.865127682685852,
      "eval_runtime": 1037.796,
      "eval_samples_per_second": 1.445,
      "eval_steps_per_second": 0.482,
      "step": 42
    },
    {
      "epoch": 1.16,
      "learning_rate": 3.972890862351017e-05,
      "loss": 0.8549,
      "step": 50
    },
    {
      "epoch": 1.4,
      "learning_rate": 3.963542883851367e-05,
      "loss": 0.7554,
      "step": 60
    },
    {
      "epoch": 1.63,
      "learning_rate": 3.9541949053517184e-05,
      "loss": 0.7382,
      "step": 70
    },
    {
      "epoch": 1.86,
      "learning_rate": 3.944846926852068e-05,
      "loss": 0.6987,
      "step": 80
    },
    {
      "epoch": 1.95,
      "eval_auc": 0.6729499544664294,
      "eval_loss": 0.6811361312866211,
      "eval_runtime": 1037.5492,
      "eval_samples_per_second": 1.446,
      "eval_steps_per_second": 0.482,
      "step": 84
    },
    {
      "epoch": 2.09,
      "learning_rate": 3.935498948352419e-05,
      "loss": 0.7169,
      "step": 90
    },
    {
      "epoch": 2.33,
      "learning_rate": 3.92615096985277e-05,
      "loss": 0.6549,
      "step": 100
    },
    {
      "epoch": 2.56,
      "learning_rate": 3.91680299135312e-05,
      "loss": 0.6375,
      "step": 110
    },
    {
      "epoch": 2.79,
      "learning_rate": 3.9074550128534705e-05,
      "loss": 0.6516,
      "step": 120
    },
    {
      "epoch": 2.93,
      "eval_auc": 0.6774636421337306,
      "eval_loss": 0.6305570602416992,
      "eval_runtime": 1040.1057,
      "eval_samples_per_second": 1.442,
      "eval_steps_per_second": 0.481,
      "step": 126
    },
    {
      "epoch": 3.02,
      "learning_rate": 3.8981070343538216e-05,
      "loss": 0.5987,
      "step": 130
    },
    {
      "epoch": 3.26,
      "learning_rate": 3.8887590558541714e-05,
      "loss": 0.6063,
      "step": 140
    },
    {
      "epoch": 3.49,
      "learning_rate": 3.8794110773545225e-05,
      "loss": 0.6061,
      "step": 150
    },
    {
      "epoch": 3.72,
      "learning_rate": 3.870063098854873e-05,
      "loss": 0.5701,
      "step": 160
    },
    {
      "epoch": 3.91,
      "eval_auc": 0.7244753290835335,
      "eval_loss": 0.6072811484336853,
      "eval_runtime": 1039.6437,
      "eval_samples_per_second": 1.443,
      "eval_steps_per_second": 0.481,
      "step": 168
    },
    {
      "epoch": 3.95,
      "learning_rate": 3.8607151203552234e-05,
      "loss": 0.5742,
      "step": 170
    },
    {
      "epoch": 4.19,
      "learning_rate": 3.851367141855574e-05,
      "loss": 0.5393,
      "step": 180
    },
    {
      "epoch": 4.42,
      "learning_rate": 3.842019163355925e-05,
      "loss": 0.5746,
      "step": 190
    },
    {
      "epoch": 4.65,
      "learning_rate": 3.832671184856275e-05,
      "loss": 0.557,
      "step": 200
    },
    {
      "epoch": 4.88,
      "learning_rate": 3.823323206356626e-05,
      "loss": 0.5487,
      "step": 210
    },
    {
      "epoch": 4.88,
      "eval_auc": 0.7519144796754699,
      "eval_loss": 0.5935317873954773,
      "eval_runtime": 1036.4197,
      "eval_samples_per_second": 1.447,
      "eval_steps_per_second": 0.482,
      "step": 210
    },
    {
      "epoch": 5.12,
      "learning_rate": 3.813975227856976e-05,
      "loss": 0.5381,
      "step": 220
    },
    {
      "epoch": 5.35,
      "learning_rate": 3.8046272493573266e-05,
      "loss": 0.5217,
      "step": 230
    },
    {
      "epoch": 5.58,
      "learning_rate": 3.795279270857677e-05,
      "loss": 0.5121,
      "step": 240
    },
    {
      "epoch": 5.81,
      "learning_rate": 3.785931292358028e-05,
      "loss": 0.5218,
      "step": 250
    },
    {
      "epoch": 5.86,
      "eval_auc": 0.748846137925325,
      "eval_loss": 0.5877646207809448,
      "eval_runtime": 1037.2833,
      "eval_samples_per_second": 1.446,
      "eval_steps_per_second": 0.482,
      "step": 252
    },
    {
      "epoch": 6.05,
      "learning_rate": 3.7765833138583786e-05,
      "loss": 0.5078,
      "step": 260
    },
    {
      "epoch": 6.28,
      "learning_rate": 3.767235335358729e-05,
      "loss": 0.4753,
      "step": 270
    },
    {
      "epoch": 6.51,
      "learning_rate": 3.7578873568590795e-05,
      "loss": 0.4913,
      "step": 280
    },
    {
      "epoch": 6.74,
      "learning_rate": 3.74853937835943e-05,
      "loss": 0.5097,
      "step": 290
    },
    {
      "epoch": 6.84,
      "eval_auc": 0.7473593978530231,
      "eval_loss": 0.5857864618301392,
      "eval_runtime": 1036.9657,
      "eval_samples_per_second": 1.447,
      "eval_steps_per_second": 0.482,
      "step": 294
    },
    {
      "epoch": 6.98,
      "learning_rate": 3.73919139985978e-05,
      "loss": 0.4931,
      "step": 300
    },
    {
      "epoch": 7.21,
      "learning_rate": 3.7298434213601314e-05,
      "loss": 0.4779,
      "step": 310
    },
    {
      "epoch": 7.44,
      "learning_rate": 3.720495442860482e-05,
      "loss": 0.4441,
      "step": 320
    },
    {
      "epoch": 7.67,
      "learning_rate": 3.711147464360832e-05,
      "loss": 0.4581,
      "step": 330
    },
    {
      "epoch": 7.81,
      "eval_auc": 0.7683358859729006,
      "eval_loss": 0.5866753458976746,
      "eval_runtime": 1036.772,
      "eval_samples_per_second": 1.447,
      "eval_steps_per_second": 0.482,
      "step": 336
    }
  ],
  "logging_steps": 10,
  "max_steps": 4300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 42,
  "total_flos": 1.66777366339584e+17,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
